{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 2023-03-30 20:07:02,546 _assert_and_prepare_model_files:199] Can NOT find model file /Users/wxf/.cnstd/1.2/analysis/mfd-yolov7_tiny.pt \n",
      "100%|██████████| 17472/17472 [00:00<00:00, 20416.46KB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /Users/wxf/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88827f76cab437980eed82462323cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 2023-03-30 20:07:05,498 _assert_and_prepare_model_files:167] no onnx file is found in /Users/wxf/.cnocr/2.2/densenet_lite_136-fc \n",
      "100%|██████████| 5579/5579 [00:00<00:00, 21387.70KB/s]\n",
      "[WARNING 2023-03-30 20:07:06,423 _assert_and_prepare_model_files:124] can not find model file /Users/wxf/.cnstd/1.2/ppocr/ch_PP-OCRv3_det_infer.onnx \n",
      "2171KB [00:00, 20441.23KB/s]                          \n",
      "[WARNING 2023-03-30 20:07:06,958 _assert_and_prepare_model_files:104] can not find model file /Users/wxf/.cnocr/2.2/ppocr/en_PP-OCRv3_rec_infer.onnx \n",
      "7957KB [00:00, 11592.62KB/s]                          \n",
      "[WARNING 2023-03-30 20:07:08,450 _assert_and_prepare_model_files:124] can not find model file /Users/wxf/.cnstd/1.2/ppocr/en_PP-OCRv3_det_infer.onnx \n",
      "2171KB [00:00, 20295.80KB/s]                          \n",
      "weights.pth: 100%|██████████| 97.4M/97.4M [00:03<00:00, 27.1Mb/s]\n",
      "image_resizer.pth: 100%|██████████| 18.5M/18.5M [00:00<00:00, 22.2Mb/s]\n",
      "[WARNING 2023-03-30 20:07:16,060 _assert_and_prepare_clf_model:170] no .ckpt file is found in /Users/wxf/.pix2text/clf \n",
      "8228KB [00:00, 24325.98KB/s]                          \n",
      "[WARNING 2023-03-30 20:07:17,173 _showwarnmsg:109] /Users/wxf/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 151 must be multiple of max stride 32, updating to 160\n",
      "WARNING: --img-size 600 must be multiple of max stride 32, updating to 608\n",
      "[{'type': 'isolated', 'text': '$$\\n\\\\mathcal{L}_{\\\\mathrm{eyelid}}~\\\\equiv~\\\\sum_{t=1}^{T}\\\\sum_{v=1}^{V}\\\\mathcal{N}_{U}^{\\\\mathrm{(eyelid)}}\\\\left(\\\\left|\\\\left|\\\\hat{h}_{t,v}\\\\,-\\\\,\\\\mathcal{x}_{t,v}\\\\right|\\\\right|^{2}\\\\right)\\n$$', 'position': array([[         12,          19],\n",
      "       [        749,          19],\n",
      "       [        749,         150],\n",
      "       [         12,         150]])}]\n"
     ]
    }
   ],
   "source": [
    "from pix2text import Pix2Text\n",
    "\n",
    "img_fp = './formula.jpg'\n",
    "p2t = Pix2Text(analyzer_config=dict(model_name='mfd'))\n",
    "outs = p2t(img_fp, resized_shape=600)  # 也可以使用 `p2t.recognize(img_fp)` 获得相同的结果\n",
    "print(outs)\n",
    "# 如果只需要识别出的文字和Latex表示，可以使用下面行的代码合并所有结果\n",
    "only_text = '\\n'.join([out['text'] for out in outs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$$\\n\\\\mathcal{L}_{\\\\mathrm{eyelid}}~\\\\equiv~\\\\sum_{t=1}^{T}\\\\sum_{v=1}^{V}\\\\mathcal{N}_{U}^{\\\\mathrm{(eyelid)}}\\\\left(\\\\left|\\\\left|\\\\hat{h}_{t,v}\\\\,-\\\\,\\\\mathcal{x}_{t,v}\\\\right|\\\\right|^{2}\\\\right)\\n$$'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: p2t predict [OPTIONS]\n",
      "\n",
      "  模型预测\n",
      "\n",
      "Options:\n",
      "  --use-analyzer / --no-use-analyzer\n",
      "                                  是否使用 MFD 或者版面分析 Analyzer  [default: use-\n",
      "                                  analyzer]\n",
      "  -a, --analyzer-name [mfd|layout]\n",
      "                                  使用哪个Analyzer，MFD还是版面分析  [default: mfd]\n",
      "  -t, --analyzer-type TEXT        Analyzer使用哪个模型，'yolov7_tiny' or 'yolov7'\n",
      "                                  [default: yolov7_tiny]\n",
      "  -d, --device TEXT               使用 `cpu` 还是 `gpu` 运行代码，也可指定为特定gpu，如`cuda:0`\n",
      "                                  [default: cpu]\n",
      "  --resized-shape INTEGER         把图片宽度resize到此大小再进行处理  [default: 600]\n",
      "  -i, --img-file-or-dir TEXT      输入图片的文件路径或者指定的文件夹  [required]\n",
      "  --save-analysis-res TEXT        把解析结果存储到此文件或目录中（如果'--img-file-or-\n",
      "                                  dir'为文件/文件夹，则'--save-analysis-\n",
      "                                  res'也应该是文件/文件夹）。取值为 `None` 表示不存储\n",
      "  -l, --log-level TEXT            Log Level, such as `INFO`, `DEBUG`\n",
      "                                  [default: INFO]\n",
      "  -h, --help                      Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "! p2t predict -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: IMAGE_PATH=./figs\n",
      "env: SAVE_FOLDER=./outputs\n"
     ]
    }
   ],
   "source": [
    "%env IMAGE_PATH=./figs\n",
    "# ! echo $IMAGE_PATH\n",
    "\n",
    "%env SAVE_FOLDER=./outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2023-03-30 20:19:46,858 select_device:104] YOLOv7 🚀 2023-3-30 torch 1.13.1 CPU\n",
      " \n",
      "[INFO 2023-03-30 20:19:46,858 __init__:161] Use model: /Users/wxf/.cnstd/1.2/analysis/mfd-yolov7_tiny.pt \n",
      "[INFO 2023-03-30 20:19:47,366 __init__:597]  \n",
      "[INFO 2023-03-30 20:19:47,689 _get_model:178] use model: /Users/wxf/.cnocr/2.2/densenet_lite_136-fc/cnocr-v2.2-densenet_lite_136-fc-epoch=039-complete_match_epoch=0.8597-model.onnx \n",
      "[INFO 2023-03-30 20:19:47,794 _assert_and_prepare_model_files:135] use model: /Users/wxf/.cnstd/1.2/ppocr/ch_PP-OCRv3_det_infer.onnx \n",
      "[INFO 2023-03-30 20:19:47,914 _assert_and_prepare_model_files:110] use model: /Users/wxf/.cnocr/2.2/ppocr/en_PP-OCRv3_rec_infer.onnx \n",
      "[INFO 2023-03-30 20:19:48,092 _assert_and_prepare_model_files:135] use model: /Users/wxf/.cnstd/1.2/ppocr/en_PP-OCRv3_det_infer.onnx \n",
      "[INFO 2023-03-30 20:19:48,214 download_checkpoints:50] use model weights.pth from path /Users/wxf/.pix2text/formular \n",
      "[INFO 2023-03-30 20:19:48,214 download_checkpoints:50] use model image_resizer.pth from path /Users/wxf/.pix2text/formular \n",
      "WARNING: --img-size 776 must be multiple of max stride 32, updating to 800\n",
      "WARNING: --img-size 600 must be multiple of max stride 32, updating to 608\n",
      "[WARNING 2023-03-30 20:19:49,527 _showwarnmsg:109] /Users/wxf/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " \n",
      "[INFO 2023-03-30 20:19:49,549 _analyze_one:338] Done. (250.4ms) Inference, (1.3ms) NMS \n",
      "2023-03-30 20:19:56.891707 [E:onnxruntime:, sequential_executor.cc:494 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'195_bn_nchwc' Status Message: Invalid input shape: {4,0}\n",
      "2023-03-30 20:19:57.459344 [E:onnxruntime:, sequential_executor.cc:494 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'195_bn_nchwc' Status Message: Invalid input shape: {4,0}\n",
      "2023-03-30 20:19:57.739144 [E:onnxruntime:, sequential_executor.cc:494 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'195_bn_nchwc' Status Message: Invalid input shape: {4,0}\n",
      "[INFO 2023-03-30 20:19:58,126 save_layout_img:291]  The image with the result is saved in: ./outputs/analysis-NIPS19-Deep Learning without Weight Transport.jpg \n",
      "[INFO 2023-03-30 20:19:58,149 predict:119] In image: ./figs/NIPS19-Deep Learning without Weight Transport.jpg\n",
      "Outs: \n",
      "\t[{'position': array([[        178,         124],\n",
      "       [        840,         124],\n",
      "       [        840,         141],\n",
      "       [        178,         141]], dtype=float32),\n",
      "  'text': 'There are of course other questions about the biological '\n",
      "          'implications of deep-learning algorithms',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,         139],\n",
      "       [        844,         139],\n",
      "       [        844,         162],\n",
      "       [        176,         162]], dtype=float32),\n",
      "  'text': 'some of which we touch on in AppendixC but in this paper our main '\n",
      "          'concern is with weight',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,         158],\n",
      "       [        245,         158],\n",
      "       [        245,         181],\n",
      "       [        176,         181]], dtype=float32),\n",
      "  'text': 'transport.',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        181,         210],\n",
      "       [        191,         210],\n",
      "       [        191,         218],\n",
      "       [        181,         218]], dtype=float32),\n",
      "  'text': '2',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        200,         203],\n",
      "       [        470,         203],\n",
      "       [        470,         225],\n",
      "       [        200,         225]], dtype=float32),\n",
      "  'text': 'The weight-transport problem',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         242],\n",
      "       [        844,         242],\n",
      "       [        844,         265],\n",
      "       [        178,         265]], dtype=float32),\n",
      "  'text': 'In atypical deep-learning network, some signals flow along a '\n",
      "          'forward path through multiple layers of',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        180,         261],\n",
      "       [        839,         261],\n",
      "       [        839,         278],\n",
      "       [        180,         278]], dtype=float32),\n",
      "  'text': 'processing units from the input layer to the output, while other '\n",
      "          'signals flow back from the output layer',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         280],\n",
      "       [        840,         280],\n",
      "       [        840,         297],\n",
      "       [        178,         297]], dtype=float32),\n",
      "  'text': 'along a feedback path. Forward-path signals perform inference (e.g. '\n",
      "          'they try to infer what objects are',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,         297],\n",
      "       [        844,         297],\n",
      "       [        844,         320],\n",
      "       [        176,         320]], dtype=float32),\n",
      "  'text': 'depicted in a visual input) while the feedback path conveys rror '\n",
      "          'signals that guide learning. In the',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         318],\n",
      "       [        527,         318],\n",
      "       [        527,         335],\n",
      "       [        178,         335]], dtype=float32),\n",
      "  'text': 'forward path, signals flow according to the equation',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        412,         339],\n",
      "       [        608,         339],\n",
      "       [        608,         366],\n",
      "       [        412,         366]]),\n",
      "  'text': '$$\\n'\n",
      "          'y_{l+1}=\\\\phi(\\\\mathbf{W}_{l+1}\\\\,\\\\mathbf{y}_{l}+\\\\mathbf{b}_{l+1})\\n'\n",
      "          '$$',\n",
      "  'type': 'isolated'},\n",
      " {'position': array([[        819,         347],\n",
      "       [        840,         347],\n",
      "       [        840,         363],\n",
      "       [        819,         363]], dtype=float32),\n",
      "  'text': '(1)',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        180,         371],\n",
      "       [        840,         371],\n",
      "       [        840,         388],\n",
      "       [        180,         388]], dtype=float32),\n",
      "  'text': 'Here $\\\\mathbf{y}_{i}$ is the output signal of layer l,i.e. a '\n",
      "          'vector whose i-th element is the activity of unitiin layer',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,         388],\n",
      "       [        842,         388],\n",
      "       [        842,         411],\n",
      "       [        176,         411]], dtype=float32),\n",
      "  'text': 'l. Equationlshows how the next layer ${\\\\mathit{l}}+1$ processes '\n",
      "          'its input yi: it multiplies y by the forward',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,         407],\n",
      "       [        846,         407],\n",
      "       [        846,         430],\n",
      "       [        176,         430]], dtype=float32),\n",
      "  'text': 'weight matrix Wi+1., adds a bias vector bi:+1, and puts the sum '\n",
      "          'through an activation function $\\\\phi.$ ',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,         425],\n",
      "       [        844,         425],\n",
      "       [        844,         447],\n",
      "       [        176,         447]], dtype=float32),\n",
      "  'text': 'Interpreted as parts of a real neuronal network in the brain, the '\n",
      "          \"y's might be vectors of neuronal firing\",\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         443],\n",
      "       [        840,         443],\n",
      "       [        840,         461],\n",
      "       [        178,         461]], dtype=float32),\n",
      "  'text': 'rates, or some function of those rates, $\\\\mathbf{W}_{l+1}$ might '\n",
      "          'be arrays of synaptic weights, and '\n",
      "          '$[{\\\\mathfrak{D}}_{\\\\downarrow-1}$ and $\\\\scriptstyle{\\\\phi}$ ',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        180,         462],\n",
      "       [        487,         462],\n",
      "       [        487,         480],\n",
      "       [        180,         480]], dtype=float32),\n",
      "  'text': 'bias currents and nonlinearities in the neurons',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         488],\n",
      "       [        841,         488],\n",
      "       [        841,         509],\n",
      "       [        178,         509]], dtype=float32),\n",
      "  'text': 'In the feedback path, error signals $\\\\delta$ flow through the '\n",
      "          'network from its output layer according to the',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,         507],\n",
      "       [        513,         507],\n",
      "       [        513,         529],\n",
      "       [        176,         529]], dtype=float32),\n",
      "  'text': 'error-backpropagation [L1] or backprop equation:',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        428,         531],\n",
      "       [        595,         531],\n",
      "       [        595,         560],\n",
      "       [        428,         560]]),\n",
      "  'text': '$$\\n'\n",
      "          '\\\\delta_{l}=\\\\phi^{\\\\prime}({\\\\bf y}_{l})\\\\ {\\\\bf W}_{l+1}^{T}\\\\ '\n",
      "          '\\\\delta_{l+1}\\n'\n",
      "          '$$',\n",
      "  'type': 'isolated'},\n",
      " {'position': array([[        819,         536],\n",
      "       [        842,         536],\n",
      "       [        842,         557],\n",
      "       [        819,         557]], dtype=float32),\n",
      "  'text': '(2)',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         562],\n",
      "       [        842,         562],\n",
      "       [        842,         584],\n",
      "       [        178,         584]], dtype=float32),\n",
      "  'text': 'Here $\\\\phi^{\\\\prime}$ is the derivative of the activation function '\n",
      "          'd from equation $({\\\\overline{{1}}}),$ which can be computed from',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        174,         577],\n",
      "       [        842,         577],\n",
      "       [        842,         603],\n",
      "       [        174,         603]], dtype=float32),\n",
      "  'text': 'Si.S $\\\\phi^{\\\\prime}$ eedback signals pas aye y Taye hrough '\n",
      "          'weighis Wf $({\\\\overline{{1}}}),$ erpe sa stcture in h',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,         598],\n",
      "       [        844,         598],\n",
      "       [        844,         620],\n",
      "       [        176,         620]], dtype=float32),\n",
      "  'text': 'brain, the feedback path might be another set of neurons, distict '\n",
      "          'from tiose in the forward path, or',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,         617],\n",
      "       [        844,         617],\n",
      "       [        844,         639],\n",
      "       [        176,         639]], dtype=float32),\n",
      "  'text': 'the same set of neurons might carry inference signals in one '\n",
      "          'direction and errs in the other [1213]',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         646],\n",
      "       [        840,         646],\n",
      "       [        840,         663],\n",
      "       [        178,         663]], dtype=float32),\n",
      "  'text': 'Either way, we have the problem that the same weight matrix '\n",
      "          '$\\\\mathbf{W}_{l}$ appears in the forward equation $\\\\ '\n",
      "          '({\\\\bar{1}})$ ',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        178,         665],\n",
      "       [        840,         665],\n",
      "       [        840,         682],\n",
      "       [        178,         682]], dtype=float32),\n",
      "  'text': 'and then again, transposed, in the feedback equation (2), whereas '\n",
      "          'in the brain, the synapses in the',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        174,         679],\n",
      "       [        842,         679],\n",
      "       [        842,         703],\n",
      "       [        174,         703]], dtype=float32),\n",
      "  'text': 'forward and feedback paths are physically ditinct withi no known '\n",
      "          'way to coordinate themselves so',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,         701],\n",
      "       [        508,         701],\n",
      "       [        508,         718],\n",
      "       [        176,         718]], dtype=float32),\n",
      "  'text': 'one set is always the transpose of the other $[1,2]$ ',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        180,         748],\n",
      "       [        203,         748],\n",
      "       [        203,         760],\n",
      "       [        180,         760]], dtype=float32),\n",
      "  'text': '3',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        198,         746],\n",
      "       [        382,         746],\n",
      "       [        382,         763],\n",
      "       [        198,         763]], dtype=float32),\n",
      "  'text': 'Feedback alignment',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        180,         785],\n",
      "       [        840,         785],\n",
      "       [        840,         803],\n",
      "       [        180,         803]], dtype=float32),\n",
      "  'text': 'In feedback alignment, the problem is avoided by replacing the '\n",
      "          'transposed $\\\\mathbf{W}_{l}{}^{\\\\cdot}{\\\\mathbf{s}}$ in the '\n",
      "          'feedback path',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        178,         804],\n",
      "       [        533,         804],\n",
      "       [        533,         822],\n",
      "       [        178,         822]], dtype=float32),\n",
      "  'text': 'by random, fixed (non-learning) weight matrices B,',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        429,         826],\n",
      "       [        592,         826],\n",
      "       [        592,         851],\n",
      "       [        429,         851]]),\n",
      "  'text': '$$\\n'\n",
      "          '\\\\delta_{l}=\\\\phi^{\\\\prime}(y_{l})\\\\:\\\\mathrm{B}_{l+1}\\\\:\\\\delta_{l+1}\\n'\n",
      "          '$$',\n",
      "  'type': 'isolated'},\n",
      " {'position': array([[        817,         828],\n",
      "       [        844,         828],\n",
      "       [        844,         851],\n",
      "       [        817,         851]], dtype=float32),\n",
      "  'text': '(3）',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,         858],\n",
      "       [        696,         858],\n",
      "       [        696,         875],\n",
      "       [        178,         875]], dtype=float32),\n",
      "  'text': 'These feedback signals $\\\\delta$ drive learning in the forward '\n",
      "          'weights $\\\\mathbf{W}$ by the rule',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        421,         881],\n",
      "       [        603,         881],\n",
      "       [        603,         908],\n",
      "       [        421,         908]]),\n",
      "  'text': '$$\\n'\n",
      "          '\\\\Delta{\\\\bf W}_{l+1}=-\\\\eta_{W}\\\\;\\\\delta_{l+1}\\\\;{\\\\bf '\n",
      "          'y}_{l}^{T}\\n'\n",
      "          '$$',\n",
      "  'type': 'isolated'},\n",
      " {'position': array([[        817,         887],\n",
      "       [        842,         887],\n",
      "       [        842,         908],\n",
      "       [        817,         908]], dtype=float32),\n",
      "  'text': '(4)',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,         914],\n",
      "       [        840,         914],\n",
      "       [        840,         932],\n",
      "       [        176,         932]], dtype=float32),\n",
      "  'text': 'where rnw is a learning-rate factor. As shown in '\n",
      "          '$\\\\left[\\\\Omega\\\\right],$ equations $(\\\\mathbb{1}),(\\\\mathbb{3}),$ '\n",
      "          'and $({\\\\bar{4}})$ together drive the',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,         930],\n",
      "       [        844,         930],\n",
      "       [        844,         952],\n",
      "       [        176,         952]], dtype=float32),\n",
      "  'text': 'forward matrices W to become roughly proportional to transposes of '\n",
      "          'the feedback matrices $\\\\mathbf{B}_{l}$ ',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,         949],\n",
      "       [        844,         949],\n",
      "       [        844,         971],\n",
      "       [        176,         971]], dtype=float32),\n",
      "  'text': 'That rough transposition makes equation 3) similar enough to the '\n",
      "          'backprop equation $\\\\left(\\\\mathbb{Z}\\\\right)$ that the',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        178,         969],\n",
      "       [        559,         969],\n",
      "       [        559,         987],\n",
      "       [        178,         987]], dtype=float32),\n",
      "  'text': 'network can learn simple tasks as well as backprop does.',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,         995],\n",
      "       [        844,         995],\n",
      "       [        844,        1018],\n",
      "       [        176,        1018]], dtype=float32),\n",
      "  'text': 'Can feedback alignment be augmented to handle harder tasks? One '\n",
      "          'approach is to adjust the feedback',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,        1012],\n",
      "       [        844,        1012],\n",
      "       [        844,        1035],\n",
      "       [        176,        1035]], dtype=float32),\n",
      "  'text': 'weights $\\\\mathbf{B}_{l}$ as well as the forward weights Wi, to '\n",
      "          'improve their agreement. Here we show two',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        178,        1033],\n",
      "       [        840,        1033],\n",
      "       [        840,        1050],\n",
      "       [        178,        1050]], dtype=float32),\n",
      "  'text': 'mechanisms by which that adjustment can be achieved quickly and '\n",
      "          'accurately in large networks',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        176,        1048],\n",
      "       [        349,        1048],\n",
      "       [        349,        1066],\n",
      "       [        176,        1066]], dtype=float32),\n",
      "  'text': 'without weight transport.',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        181,        1100],\n",
      "       [        193,        1100],\n",
      "       [        193,        1109],\n",
      "       [        181,        1109]], dtype=float32),\n",
      "  'text': '4',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        200,        1097],\n",
      "       [        342,        1097],\n",
      "       [        342,        1114],\n",
      "       [        200,        1114]], dtype=float32),\n",
      "  'text': 'Weight mirrors',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        180,        1138],\n",
      "       [        205,        1138],\n",
      "       [        205,        1152],\n",
      "       [        180,        1152]], dtype=float32),\n",
      "  'text': '4.1',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        200,        1136],\n",
      "       [        382,        1136],\n",
      "       [        382,        1153],\n",
      "       [        200,        1153]], dtype=float32),\n",
      "  'text': 'Learning the transpose',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        178,        1167],\n",
      "       [        839,        1167],\n",
      "       [        839,        1184],\n",
      "       [        178,        1184]], dtype=float32),\n",
      "  'text': 'The aim here is to adjust an initially random matrix $\\\\mathbf{B}$ '\n",
      "          'so it becomes proportional to the transpose',\n",
      "  'type': 'text-embed'},\n",
      " {'position': array([[        176,        1184],\n",
      "       [        844,        1184],\n",
      "       [        844,        1207],\n",
      "       [        176,        1207]], dtype=float32),\n",
      "  'text': 'of another matrix W without weight transpot, ie. given only the '\n",
      "          'input and output vectors x and',\n",
      "  'type': 'text'},\n",
      " {'position': array([[        502,        1236],\n",
      "       [        517,        1236],\n",
      "       [        517,        1255],\n",
      "       [        502,        1255]], dtype=float32),\n",
      "  'text': '2',\n",
      "  'type': 'text'}]\n",
      "Only texts: \n",
      "\tThere are of course other questions about the biological implications of deep-learning algorithms\n",
      "some of which we touch on in AppendixC but in this paper our main concern is with weight\n",
      "transport.\n",
      "2\n",
      "The weight-transport problem\n",
      "In atypical deep-learning network, some signals flow along a forward path through multiple layers of\n",
      "processing units from the input layer to the output, while other signals flow back from the output layer\n",
      "along a feedback path. Forward-path signals perform inference (e.g. they try to infer what objects are\n",
      "depicted in a visual input) while the feedback path conveys rror signals that guide learning. In the\n",
      "forward path, signals flow according to the equation\n",
      "$$\n",
      "y_{l+1}=\\phi(\\mathbf{W}_{l+1}\\,\\mathbf{y}_{l}+\\mathbf{b}_{l+1})\n",
      "$$\n",
      "(1)\n",
      "Here $\\mathbf{y}_{i}$ is the output signal of layer l,i.e. a vector whose i-th element is the activity of unitiin layer\n",
      "l. Equationlshows how the next layer ${\\mathit{l}}+1$ processes its input yi: it multiplies y by the forward\n",
      "weight matrix Wi+1., adds a bias vector bi:+1, and puts the sum through an activation function $\\phi.$ \n",
      "Interpreted as parts of a real neuronal network in the brain, the y's might be vectors of neuronal firing\n",
      "rates, or some function of those rates, $\\mathbf{W}_{l+1}$ might be arrays of synaptic weights, and $[{\\mathfrak{D}}_{\\downarrow-1}$ and $\\scriptstyle{\\phi}$ \n",
      "bias currents and nonlinearities in the neurons\n",
      "In the feedback path, error signals $\\delta$ flow through the network from its output layer according to the\n",
      "error-backpropagation [L1] or backprop equation:\n",
      "$$\n",
      "\\delta_{l}=\\phi^{\\prime}({\\bf y}_{l})\\ {\\bf W}_{l+1}^{T}\\ \\delta_{l+1}\n",
      "$$\n",
      "(2)\n",
      "Here $\\phi^{\\prime}$ is the derivative of the activation function d from equation $({\\overline{{1}}}),$ which can be computed from\n",
      "Si.S $\\phi^{\\prime}$ eedback signals pas aye y Taye hrough weighis Wf $({\\overline{{1}}}),$ erpe sa stcture in h\n",
      "brain, the feedback path might be another set of neurons, distict from tiose in the forward path, or\n",
      "the same set of neurons might carry inference signals in one direction and errs in the other [1213]\n",
      "Either way, we have the problem that the same weight matrix $\\mathbf{W}_{l}$ appears in the forward equation $\\ ({\\bar{1}})$ \n",
      "and then again, transposed, in the feedback equation (2), whereas in the brain, the synapses in the\n",
      "forward and feedback paths are physically ditinct withi no known way to coordinate themselves so\n",
      "one set is always the transpose of the other $[1,2]$ \n",
      "3\n",
      "Feedback alignment\n",
      "In feedback alignment, the problem is avoided by replacing the transposed $\\mathbf{W}_{l}{}^{\\cdot}{\\mathbf{s}}$ in the feedback path\n",
      "by random, fixed (non-learning) weight matrices B,\n",
      "$$\n",
      "\\delta_{l}=\\phi^{\\prime}(y_{l})\\:\\mathrm{B}_{l+1}\\:\\delta_{l+1}\n",
      "$$\n",
      "(3）\n",
      "These feedback signals $\\delta$ drive learning in the forward weights $\\mathbf{W}$ by the rule\n",
      "$$\n",
      "\\Delta{\\bf W}_{l+1}=-\\eta_{W}\\;\\delta_{l+1}\\;{\\bf y}_{l}^{T}\n",
      "$$\n",
      "(4)\n",
      "where rnw is a learning-rate factor. As shown in $\\left[\\Omega\\right],$ equations $(\\mathbb{1}),(\\mathbb{3}),$ and $({\\bar{4}})$ together drive the\n",
      "forward matrices W to become roughly proportional to transposes of the feedback matrices $\\mathbf{B}_{l}$ \n",
      "That rough transposition makes equation 3) similar enough to the backprop equation $\\left(\\mathbb{Z}\\right)$ that the\n",
      "network can learn simple tasks as well as backprop does.\n",
      "Can feedback alignment be augmented to handle harder tasks? One approach is to adjust the feedback\n",
      "weights $\\mathbf{B}_{l}$ as well as the forward weights Wi, to improve their agreement. Here we show two\n",
      "mechanisms by which that adjustment can be achieved quickly and accurately in large networks\n",
      "without weight transport.\n",
      "4\n",
      "Weight mirrors\n",
      "4.1\n",
      "Learning the transpose\n",
      "The aim here is to adjust an initially random matrix $\\mathbf{B}$ so it becomes proportional to the transpose\n",
      "of another matrix W without weight transpot, ie. given only the input and output vectors x and\n",
      "2 \n"
     ]
    }
   ],
   "source": [
    "! p2t predict --use-analyzer -i ${IMAGE_PATH} --save-analysis-res ${SAVE_FOLDER}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
